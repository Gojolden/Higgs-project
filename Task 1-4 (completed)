import numpy as np
import matplotlib.pyplot as plt
from scipy.optimize import curve_fit
from matplotlib.ticker import AutoMinorLocator
from scipy.stats import chi2
plt.rcParams["text.usetex"] = False
# %%

# Task 1 Start ---------------------------------------------------------------

np.random.seed(1)

N_b = 10e5  # Number of background events, used in generation and in fit.
b_tau = 30.  # Spoiler.


def generate_signal(N, mu, sig):
    '''
    Generate N values according to a gaussian distribution.
    '''
    return np.random.normal(loc=0, scale=1, size=400).tolist()


# %%

def generate_background(N, tau):
    '''
    Generate N values according to an exp distribution.
    '''

    return np.random.exponential(scale=tau, size=int(N)).tolist()


def generate_data(n_signals=200):
    '''
    Generate a set of values for signal and background. Input arguement sets
    the number of signal events, and can be varied (default to higgs-like at
    announcement).

    The background amplitude is fixed to 9e5 events, and is modelled as an
    exponential, hard coded width. The signal is modelled as a gaussian on top
    (again, hard coded width and mu).
    '''
    vals = []
    vals += generate_signal(n_signals, 125., 1.5)
    vals += generate_background(N_b, b_tau)

    return vals


vals = generate_data()

# np.savetxt('Documents/vals.txt', vals)
# commenting this out so a different vals file doesn't override the already
# stored one.
# %%
# calling the generated values


g_vals = np.loadtxt("Documents/vals.txt", skiprows=2, delimiter=' ',
                    unpack=True)
# %%

# Make a histogram.
bin_heights, bin_edges, patches = plt.hist(g_vals, range=[104, 155], bins=30)
params = {
   'axes.labelsize': 8,
   'font.size': 8,
   'legend.fontsize': 8,
   'xtick.labelsize': 8,
   'ytick.labelsize': 8,
   'figure.figsize': [5, 8.09]  # using golden ratio
   }
bins_c1 = plt.hist(vals, range=[50, 200], bins=30, color='red',
                   label='50-200')

bins_main = plt.hist(g_vals, range=[104, 155], bins=30, color='green',
                     label='104-155')

bins_c2 = plt.hist(vals, range=[120, 150], bins=30, color='blue',
                   label='120-150')
bincentres = 0.5 * (bins_main[1][1:] + bins_main[1][:-1])
bin_widths = bin_edges[1:] - bin_edges[:-1]
# calculate the bin centres (i.e. x position of the error bars)
print('x coordinates of bincentres are', bincentres)
print('y coordinates of bincentres are', bin_heights)
# %%

params = {
   'axes.labelsize': 8,
   'font.size': 14,
   'legend.fontsize': 8,
   'xtick.labelsize': 12,
   'ytick.labelsize': 12,
   'figure.figsize': [8, 6]  # using golden ratio
   }
plt.errorbar(bincentres, bins_c1[0], yerr=np.sqrt(bins_c1[0]), color='red',
             fmt='o', mew=2, ms=3, capsize=4)  # plot the error bars.

plt.errorbar(bincentres, bins_main[0], yerr=np.sqrt(bins_main[0]),
             color='green', fmt='o', mew=2, ms=3, capsize=4)
# plot the error bars.

plt.errorbar(bincentres, bins_c2[0], yerr=np.sqrt(bins_c2[0]), color='blue',
             fmt='o', mew=2, ms=3, capsize=4)  # plot the error bars.

plt.xlabel(r'$m_{\gamma\gamma}$ (GeV)', loc='right')
plt.ylabel("Number of entries")
plt.legend(['Data points - range: 50-200', 'Data points - range: 104-155',
            'Data points - range: 120-150'], loc='upper right', fontsize=12,
           frameon=False)
plt.xticks(fontsize=12)
plt.yticks(fontsize=12)
plt.tight_layout()
plt.show()
# bin_heights and bin_edges are numpy arrays.
# patches are the matplotlib bar objects, which we won’t need.
# For larger bin sizes, signal disappears
# %%
plt.errorbar(bincentres, bin_heights, yerr=np.sqrt(bin_heights),
             xerr=bin_widths/2, color='black',
             fmt='.', mew=2, ms=7, capsize=0.7)  # plot the error bars.
plt.xlabel(r'$m_{\gamma\gamma}$ (GeV)', loc='right', fontsize=14)
plt.ylabel("Number of entries", fontsize=14)
# plt.legend(['Data points',], loc='upper right', fontsize=12, frameon=False)
plt.xticks(fontsize=12)
plt.yticks(fontsize=12)
# Ticks inside
plt.tick_params(axis='both', which='both', direction='in')

# parameters for graph given below got through Chatgpt
# Minor ticks
plt.gca().xaxis.set_minor_locator(AutoMinorLocator())
plt.gca().yaxis.set_minor_locator(AutoMinorLocator())
plt.tick_params(axis='both', which='major', length=7)
plt.tick_params(axis='both', which='minor', length=4)
plt.figure(figsize=(6.5, 10))
# plt.tight_layout()
plt.show()
# Task 1 end -----------------------------------------------------------------

# %%

# Task 2 start ---------------------------------------------------------------
# importing functions
# The function is defined to generate background expectation values


def get_B_expectation(xs, A, lamb):
    '''
    Return a set of expectation values for the background distribution for the
    passed in x values.
    '''
    return [A*np.exp(-x/lamb) for x in xs]


def signal_gaus(x, mu, sig, signal_amp):
    return signal_amp/(np.sqrt(2.*np.pi)*sig)*np.exp(-np.power((x - mu)/sig,
                                                               2.)/2)

# Function generates background plus signal values


def get_SB_expectation(xs, A, lamb, mu, sig, signal_amp):
    ys = []
    for x in xs:
        ys.append(A*np.exp(-x/lamb) + signal_gaus(x, mu, sig, signal_amp))
    return ys
# %%
# Removing values corresponding to signal so that our parameterization includes
# only the background to get accurate values for lambda and A.
# creating a boolean mask


B_vals = np.array(generate_background(N_b, b_tau))
B_vals_nosig = B_vals[(B_vals < 120) | (B_vals > 130)]

# doing maximum likelihood method on paper, find λ_hat = mean of values not
# including signal vals
λ_hat_MLE = np.mean(B_vals_nosig)

# integrating PDF (Ae^(-x/λ)) between 104 and 155 and setting equal to N to
# find A.
# vals_in_range = B_vals_nosig[(B_vals_nosig < 104) | (B_vals_nosig > 155)].
# Range achieved through trial and error to scale try and scale closest to the
# observed distribution.
vals_in_range = [P for P in B_vals_nosig if 89 <= P <= 180]
N = len(vals_in_range)


A_MLE = N/(λ_hat_MLE * (np.exp(-104/λ_hat_MLE) - np.exp(-155/λ_hat_MLE)))

# Calculating the uncertainty on the MLE of λ
sig_λ_hat_MLE = λ_hat_MLE/np.sqrt(N)

print('The MLE of λ is', λ_hat_MLE)
print('The corresponding A value is', A_MLE)
print('The uncertainty on the MLE of λ is', sig_λ_hat_MLE)
# %%

# Fitting the background + signal to data, red line should have a 'bump'
# around 125, if not, change initial guesses.

initial_guess = [A_MLE, λ_hat_MLE, 125, 1.5, 300]
po, po_cov = curve_fit(get_SB_expectation, bincentres, bin_heights,
                       initial_guess, sig_λ_hat_MLE, maxfev=500)

# print("The parameters")
# print(po)
# print('The covariance matrix')
# print(po_cov)

print("The signal parameters are")
print(f" A = {po[0]:.1f} +/- {np.sqrt(po_cov[0, 0]):.1f}")
print(f" lamb = {po[1]:.1f} +/- {np.sqrt(po_cov[1,1]):.1f}")
print(f" mu = {po[2]:.1f} +/- {np.sqrt(po_cov[2, 2]):.1f}")
print("and the background estimate is")
print(f" sig = {po[3]:.2f} +/- {np.sqrt(po_cov[3, 3]):.2f}")
print(f" signal_amp = {po[4]:.0f} +/- {np.sqrt(po_cov[4, 4]):.0f}")


plt.errorbar(bincentres, bin_heights, yerr=np.sqrt(bin_heights),
             xerr=bin_widths/2, color='black', fmt='o', mew=2, ms=4,
             capsize=0.7)
# plot the error bars.
plt.plot(bincentres, get_SB_expectation(bincentres, po[0], po[1], po[2],
                                        po[3], po[4]), label='Fit results',
         color='r')
plt.xlabel(r'$m_{\gamma\gamma}$ (GeV)', loc='right', fontsize=14)
plt.ylabel("Number of entries", fontsize=14)
plt.xticks(fontsize=12)
plt.yticks(fontsize=12)
# Ticks inside
plt.tick_params(axis='both', which='both', direction='in')

# parameters for graph given below got through Chatgpt
# Minor ticks
plt.gca().xaxis.set_minor_locator(AutoMinorLocator())
plt.gca().yaxis.set_minor_locator(AutoMinorLocator())
plt.tick_params(axis='both', which='major', length=7)
plt.tick_params(axis='both', which='minor', length=4)
plt.legend(['B+S fit', 'Data points'], loc='upper right', fontsize=12,
           frameon=False)
plt.tight_layout()
plt.show()
# %%

# plotting the background
expected_MLE = get_B_expectation(bincentres, A_MLE, λ_hat_MLE)
plt.plot(bincentres, get_SB_expectation(bincentres, po[0], po[1], po[2],
                                        po[3], po[4]), label='Fit results',
         color='r')
plt.plot(bincentres, expected_MLE, 'g--', lw=1.5, label='MLE Fit',
         color='blue',)
plt.fill_between(bincentres, expected_MLE-(sig_λ_hat_MLE),
                 # got plt.fill_between from chatgpt
                 expected_MLE+(sig_λ_hat_MLE), color='green', alpha=1,
                 step='mid', label='B uncertainty')
plt.errorbar(bincentres, bin_heights, yerr=np.sqrt(bin_heights),
             xerr=bin_widths/2, color='black', fmt='o', mew=3, ms=3,
             capsize=1)
# plot the error bars.
plt.xlabel(r'$m_{\gamma\gamma}$ (GeV)', loc='right', fontsize=14)
plt.ylabel("Number of entries", fontsize=14)
plt.xticks(fontsize=12)
plt.yticks(fontsize=12)
# Ticks inside
plt.tick_params(axis='both', which='both', direction='in')

# parameters for graph given below got through Chatgpt
# Minor ticks
plt.gca().xaxis.set_minor_locator(AutoMinorLocator())
plt.gca().yaxis.set_minor_locator(AutoMinorLocator())
plt.tick_params(axis='both', which='major', length=7)
plt.tick_params(axis='both', which='minor', length=4)
plt.legend(['B + S fit', 'B (MLE method)', 'B uncertainty', 'Data points'],
           loc='upper right', fontsize=12, frameon=False)
plt.tight_layout()
plt.show()

# Task 2 end -----------------------------------------------------------------

# %%

# Task 3 start ---------------------------------------------------------------


# The function is defined to generate background expectation values
#def get_B_expectation(xs, A, lamb):
    #return A * np.exp(-xs / lamb)


# The function is used to generate chi square function
def get_B_chi(vals, histo_range, n_bins, A, lamb):
    bin_heights, bin_edges = np.histogram(g_vals, range=histo_range,
                                          bins=n_bins)
    bin_centres = 0.5 * (bin_edges[1:] + bin_edges[:-1])
    expected = get_B_expectation(bin_centres, A, lamb)

    errors = np.sqrt(bin_heights)
    errors[errors == 0] = 1e-6  # in case division by 0 in the functions

    chi2 = np.sum(((bin_heights - expected) ** 2) / errors ** 2)
    return chi2


# Parameters for the histogram
range_low, range_up = 104, 155
n_bins = 30
bin_centres = np.linspace(range_low + (range_up - range_low) / (2 * n_bins),
                          range_up - (range_up - range_low) / (2 * n_bins),
                          n_bins)

vals = generate_data()

# Choose scan ranges for A and Lambda
A_vals = np.linspace(1e3, 1e5, 100)  # Try values from 1000 to 100000
lamb_vals = np.linspace(20, 40, 100)  # Try values from 20 to 40

chi2_grid = np.zeros((len(A_vals), len(lamb_vals)))

# For each combination, calculate the χ² and store it.
for i, A in enumerate(A_vals):
    for j, lamb in enumerate(lamb_vals):
        chi2 = get_B_chi(vals, (range_low, range_up), n_bins, A, lamb)
        chi2_grid[i, j] = chi2

# Find where the minimum χ² occurs
min_index = np.unravel_index(np.argmin(chi2_grid), chi2_grid.shape)
best_A = A_vals[min_index[0]]
best_lamb = lamb_vals[min_index[1]]
min_chi2 = chi2_grid[min_index]

print(f"Best-fit A: {best_A}")
print(f"Best-fit lambda: {best_lamb}")
print(f"Minimum chi²: {min_chi2}")
# %%
A_chi = best_A
lambda_chi = best_lamb
expected_chi = get_B_expectation(bincentres, A_chi, lambda_chi)
# %%
plt.plot(bincentres, get_SB_expectation(bincentres, po[0], po[1], po[2], po[3],
                                        po[4]),
         label='Fit results', color='r')
plt.plot(bincentres, expected_MLE, 'g--', lw=1.5, label='MLE Fit',
         color='blue',)
plt.plot(bincentres, expected_chi, 'g--', lw=1.5, label='Min-χ² Fit',
         color='green')
plt.fill_between(bincentres, expected_MLE-(sig_λ_hat_MLE),  # got from chatgpt
                 expected_MLE+(sig_λ_hat_MLE), color='green', alpha=1,
                 step='mid', label='B uncertainty')
# plt.errorbar(x, y, yerr=y_error, fmt='o', label="Input Data", capsize=2)
plt.errorbar(bincentres, bin_heights, yerr=np.sqrt(bin_heights),
             xerr=bin_widths/2,
             color='black', fmt='o', mew=3, ms=3, capsize=1)
# plot the error bars.
plt.xlabel(r'$m_{\gamma\gamma}$ (GeV)', loc='right', fontsize=14)
plt.ylabel("Number of entries", fontsize=14)
plt.xticks(fontsize=12)
plt.yticks(fontsize=12)
# Ticks inside
plt.tick_params(axis='both', which='both', direction='in')

# parameters for graph given below got through Chatgpt
# Minor ticks
plt.gca().xaxis.set_minor_locator(AutoMinorLocator())
plt.gca().yaxis.set_minor_locator(AutoMinorLocator())
plt.tick_params(axis='both', which='major', length=7)
plt.tick_params(axis='both', which='minor', length=4)
plt.legend(['B+S fit', 'B (MLE method)', 'B (Min-χ² method)', 'B uncertainty',
            'Data points'],
           loc='upper right', fontsize=12, frameon=False)
plt.tight_layout()
plt.show()
# task 3 end -----------------------------------------------------------------
# %%
# %%

# Task 4 start ---------------------------------------------------------------


mass_range = [104, 155]  # defines mass range for histogram
nbins = 30  # number of bins for histogram
mu = 125  # Higgs mass in GeV
sig = 1.5  # standard deviation / signal width
signal_amp = 300  # signal amplitude


bin_heights, bin_edges = np.histogram(g_vals, range=mass_range, bins=nbins)
# creation of histogram
bin_centres = 0.5 * (bin_edges[:-1] + bin_edges[1:])
# calculating centre of each bin
bin_widths = bin_edges[1:] - bin_edges[:-1]
# calculating width of each bin
errors = np.sqrt(bin_heights)
# to find poisson errors for each bin
errors[errors == 0] = 1e-6
# ensuring any errors equal to 0 are replaced preventing division by 0


# Calculates expected background values and returns the chi_squared between
# the data and model.
def get_chi2_background(g_vals, observed, errors, A, lamb):
    expected = get_B_expectation(g_vals, A, lamb)
    return np.sum(((observed - expected) ** 2) / errors ** 2)


chi2_bkg = get_chi2_background(bincentres, bin_heights, errors, best_A,
                               best_lamb)  # chi_squared just for background
dof_bkg = nbins - 2  # calculation of degrees of freedom
pval_bkg = 1 - chi2.cdf(chi2_bkg, dof_bkg)  # calculation of p values

# printing results
print("--- Task 4a: Background-Only Fit ---")
print(f"Chi²: {chi2_bkg:.2f} (dof = {dof_bkg})")
print(f"p-value: {pval_bkg:.4f}")


# Same as before but for signal AND background
def get_SB_chi(vals, mass_range, nbins, A, lamb, mu, sig, amp):
    bin_heights, bin_edges = np.histogram(vals, range=mass_range, bins=nbins)
    bin_centres = 0.5 * (bin_edges[1:] + bin_edges[:-1])
    expected = get_SB_expectation(bin_centres, A, lamb, mu, sig, amp)
    errors = np.sqrt(bin_heights)
    errors[errors == 0] = 1e-6
    return np.sum(((bin_heights - expected) ** 2) / errors ** 2)


# retrieving chi_squared for signal AND background
chi2_sb = get_SB_chi(g_vals, mass_range, nbins, best_A, best_lamb, mu, sig,
                     signal_amp)
dof_sb = nbins - 5  # degrees of freedom
pval_sb = 1 - chi2.cdf(chi2_sb, dof_sb)  # p-value for signal AND background

# printing results
print("\n--- Task 4b: Signal + Background Fit ---")
print(f"Chi²: {chi2_sb:.2f} (dof = {dof_sb})")
print(f"p-value: {pval_sb:.4f}")

expected_bkg = get_B_expectation(bin_centres, best_A, best_lamb)
# calculation of expected BACKGROUND values
expected_sb = get_SB_expectation(bin_centres, best_A, best_lamb, mu, sig,
                                 signal_amp)
# calculation of expected BACKGROUND AND SIGNAL values


# graph plotting
plt.errorbar(bincentres, bin_heights, yerr=errors, xerr=bin_widths/2, fmt='o',
             color='black', mew=3, ms=3, capsize=1, label='Data')
plt.plot(bincentres, expected_bkg, linestyle='--', color='blue',
         label='Background-only')
plt.plot(bincentres, expected_sb, color='red', label='Signal + Background')
plt.xlabel(r'$m_{\gamma\gamma}$ (GeV)', loc='right', fontsize=14)
plt.ylabel("Number of entries", fontsize=14)
plt.xticks(fontsize=12)
plt.yticks(fontsize=12)
plt.tick_params(axis='both', which='both', direction='in')

# parameters for graph given below got through Chatgpt
# Minor ticks
plt.gca().xaxis.set_minor_locator(AutoMinorLocator())
plt.gca().yaxis.set_minor_locator(AutoMinorLocator())
plt.tick_params(axis='both', which='major', length=7)
plt.tick_params(axis='both', which='minor', length=4)
plt.title("Chi-squared Fit Comparison", fontsize=14)
plt.legend(loc='upper right', fontsize=12, frameon=False)
plt.tight_layout()
plt.show()

# Task 4 end -----------------------------------------------------------------
